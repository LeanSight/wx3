# wx41: Analisis de Arquitectura Pipeline para Reimplementacion

Fecha: 2026-02-28
Objetivo: Analizar los steps actuales de wx4 para reimplementar pipeline.py y cli.py
desde cero con patrones idiomaticos Python 2026.

---

## 1. Mapa de lo que existe

### 1.1 Modulos de step (wx4/steps/)

| Step | Archivo | Salida declarada | Skip logica |
|------|---------|-----------------|-------------|
| cache_check | steps/cache_check.py | ninguna | interna (lee cache JSON) |
| normalize | steps/normalize.py | `_normalized.m4a` | interna (ctx.cache_hit OR out.exists()) + pipeline |
| enhance | steps/enhance.py | `_enhanced.m4a` | interna (ctx.cache_hit AND ctx.enhanced) + pipeline |
| cache_save | steps/cache_save.py | ninguna | interna (ctx.cache_hit OR ctx.enhanced is None) |
| transcribe | steps/transcribe.py | `_timestamps.json` | solo pipeline |
| srt | steps/srt.py | `_timestamps.srt` | solo pipeline |
| video | steps/video.py | `_timestamps.mp4` | solo pipeline |
| compress | steps/compress.py | `_compressed.mp4` | solo pipeline |

### 1.2 Patron uniforme en todos los steps

Cada step sigue esta estructura identica:

```
t0 = time.time()
[logica del step]
return dataclasses.replace(ctx, ..., timings={**ctx.timings, "nombre": time.time() - t0})
```

### 1.3 Comunicacion step -> UI (actual)

Los steps NO importan Rich. La cadena de reporte es:
```
step ---> ctx.step_progress(done, total) ---> Pipeline._make_step_progress() ---> callbacks.on_step_progress()
```
`ctx.step_progress` es un `Callable[[int, int], None]` inyectado por el pipeline antes de cada step.

---

## 2. Problemas identificados en la implementacion actual

### 2.1 Doble logica de skip en normalize_step y enhance_step

`Pipeline.run()` ya maneja skip via `output_fn + output.exists()`. Pero `normalize_step`
tiene adicionalmente:
```python
if ctx.cache_hit or out.exists():
    return dataclasses.replace(ctx, normalized=out if out.exists() else ctx.normalized, ...)
```

Resultado: cuando `cache_hit=True` y el archivo normalizado no existe,
`Pipeline.run()` llama al step (no skippea), el step retorna silenciosamente,
y los callbacks reciben `on_step_start` + `on_step_end` en lugar de `on_step_skipped`.
La UI muestra el step como ejecutado cuando no lo fue. Inconsistencia observable.

### 2.2 cache_check hardcodeado en Pipeline

En `Pipeline.run()` (lineas 69-78) y `Pipeline.dry_run()` (lineas 117-125):
```python
from wx4.steps import cache_check_step
cache_check_step_fn = None
for step in self.steps:
    if hasattr(step, "fn") and step.fn is cache_check_step:
        ...
```
El runner sabe el nombre de un step especifico. Es un code smell: el pipeline
deberia ser agnositco de implementaciones de step.

### 2.3 dry_run no es completamente dry

`Pipeline.dry_run()` ejecuta `cache_check_step_fn(ctx)` (linea 126), que llama
`load_cache()`, que lee el archivo `wx4_cache.json` del filesystem.
Un dry-run puro no deberia tener efectos secundarios de lectura de estado mutable.

### 2.4 model_cache importa Rich

`wx4/model_cache.py` importa `from rich.console import Console`.
Esto viola la restriccion de que los steps no dependan de UI.
El parametro `console` es Optional y se pasa como `None` desde `enhance_step`,
pero la dependencia de import existe a nivel de modulo.

### 2.5 Boilerplate de timing repetido 8 veces

Cada step: `t0 = time.time()` + `timings={**ctx.timings, "nombre": time.time() - t0}`.
Ocho copias del mismo patron. Sin extraccion, cambiar el mecanismo de timing
requiere editar 8 archivos.

### 2.6 Patron de escritura atomica repetido

`normalize_step` y `enhance_step` usan identico patron:
```python
tmp_out = out.with_suffix(".m4a.tmp")
if not to_aac(..., tmp_out):
    raise RuntimeError(...)
tmp_out.rename(out)
```
Y ambos tienen cleanup de tmp files con `try/finally`.

### 2.7 Logica de compresion duplicada

`video_step._compress_video_from_audio()` y `compress_step` ejecutan la misma
secuencia: `probe_video -> measure_audio_lufs -> LufsInfo -> detect_best_encoder
-> calculate_video_bitrate -> compress_video`. La diferencia es solo el destino
y la fuente de audio. Logica comun no extraida.

---

## 3. Patrones Python 2026 para la reimplementacion

### 3.1 Encadenado de steps: loop explicito con callbacks (recomendado)

El patron idiomatico 2026 para pipelines secuenciales con observabilidad es el
loop explicito con callbacks, NO `functools.reduce`. Razones:

```python
ctx = functools.reduce(lambda ctx, step: step(ctx), steps, ctx)
```
Es elegante pero: (a) imposibilita inyectar step_progress por step, (b) no permite
skip logic, (c) no hay punto de insercion para callbacks. No aplica aqui.

El patron correcto es el loop actual pero con Protocol formalizado:

```python
from typing import Protocol, runtime_checkable

@runtime_checkable
class PipelineObserver(Protocol):
    def on_pipeline_start(self, step_names: list[str], ctx: PipelineContext) -> None: ...
    def on_step_start(self, name: str, ctx: PipelineContext) -> None: ...
    def on_step_end(self, name: str, ctx: PipelineContext) -> None: ...
    def on_step_skipped(self, name: str, reason: str, ctx: PipelineContext) -> None: ...
    def on_step_progress(self, name: str, done: int, total: int) -> None: ...
    def on_pipeline_end(self, ctx: PipelineContext) -> None: ...
```

`@runtime_checkable` permite `isinstance(cb, PipelineObserver)` para validacion.
La firma de `on_step_skipped` gana un `reason: str` para que la UI muestre
"already done" vs "cache hit" vs "forced skip".

### 3.2 Skip y resume: puramente basado en archivos de salida

El patron 2026 para resume de pipeline de procesamiento de archivos es la
verificacion de existencia del archivo de salida (output sentinel), NO un archivo
de estado separado (SQLite, JSON de checkpoint):

```python
@dataclass
class NamedStep:
    name: str
    fn: Callable[[PipelineContext], PipelineContext]
    output_fn: Optional[Callable[[PipelineContext], Path]] = None
    skip_fn: Optional[Callable[[PipelineContext], bool]] = None
    ctx_setter: Optional[Callable[[PipelineContext, Path], PipelineContext]] = None
```

Agregar `skip_fn` a `NamedStep` permite manejar la logica de `cache_hit` desde
el exterior del step:
```python
NamedStep(
    "normalize",
    normalize_step,
    output_fn=_NORMALIZE_OUT,
    skip_fn=lambda ctx: ctx.cache_hit,
    ctx_setter=lambda ctx, p: dataclasses.replace(ctx, normalized=p),
)
```

Asi el pipeline puede llamar `on_step_skipped(name, "cache_hit", ctx)` correctamente
y la UI se entera.

### 3.3 Escritura atomica: contextmanager reutilizable

El patron idiomatico 2026 para escrituras atomicas file-based:

```python
from contextlib import contextmanager
from pathlib import Path

@contextmanager
def atomic_output(target: Path):
    tmp = target.with_suffix(target.suffix + ".tmp")
    try:
        yield tmp
        tmp.rename(target)
    except Exception:
        if tmp.exists():
            tmp.unlink()
        raise
```

Uso en steps:
```python
with atomic_output(out) as tmp_out:
    if not to_aac(tmp_enh, tmp_out):
        raise RuntimeError(...)
```

`Path.rename()` en POSIX es atomico cuando src y dst estan en el mismo filesystem.
Es esencial que `tmp` este en el mismo directorio que `target`.

### 3.4 Timing: helper function (no decorator)

Un decorator en los steps romperia la testabilidad (los tests parchean las funciones
internas que el step llama). Un context manager es mas apropiado:

```python
from contextlib import contextmanager

@contextmanager
def step_timer(ctx: PipelineContext, step_name: str):
    t0 = time.monotonic()
    yield
    elapsed = time.monotonic() - t0
    ctx = dataclasses.replace(ctx, timings={**ctx.timings, step_name: elapsed})
```

Problema: el contextmanager no puede devolver el nuevo ctx facilmente.
Alternativa mas simple y Pythonica: una funcion helper pura.

```python
def _with_timing(ctx: PipelineContext, name: str, t0: float) -> dict:
    return {**ctx.timings, name: time.monotonic() - t0}
```

Uso: `return dataclasses.replace(ctx, ..., timings=_with_timing(ctx, "normalize", t0))`

Esto es menos boilerplate que el `contextmanager` y mas explicito.
`time.monotonic()` (no `time.time()`) es el standard 2026 para duraciones:
no es afectado por ajustes de reloj del sistema.

### 3.5 Dry-run: simulacion pura sin efectos de lectura

Para que dry_run sea verdaderamente dry, el step `cache_check` no debe ejecutarse.
En su lugar, el pipeline puede simular su efecto consultando solo el filesystem
(los archivos de salida que cache_check detectaria):

```python
def dry_run(self, ctx: PipelineContext) -> list[StepDecision]:
    simulated_ctx = _simulate_cache_check(ctx)
    for step in self.steps:
        if step.name == "cache_check":
            decisions.append(StepDecision("cache_check", True, None, "always_runs"))
            continue
        out = step.output_fn(simulated_ctx) if step.output_fn else None
        skip = (
            (step.skip_fn and step.skip_fn(simulated_ctx))
            or (out is not None and out.exists() and not simulated_ctx.force)
        )
        ...
```

`_simulate_cache_check` es una funcion pura que replica la logica de deteccion de
archivos intermedios de `cache_check_step` sin llamar `load_cache()`.

### 3.6 UI: Rich Progress con Observer desacoplado

El patron 2026 para pipelines CLI fire-and-forget:

```python
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn

class RichPipelineObserver:
    def __init__(self, console):
        self._console = console
        self._progress: Optional[Progress] = None
        self._task_ids: dict[str, TaskID] = {}

    def on_pipeline_start(self, step_names, ctx):
        self._progress = Progress(
            SpinnerColumn(),
            TextColumn("[bold]{task.description}"),
            BarColumn(),
            TimeElapsedColumn(),
            transient=True,
            console=self._console,
        )
        self._progress.start()

    def on_step_start(self, name, ctx):
        task_id = self._progress.add_task(name, total=None)
        self._task_ids[name] = task_id

    def on_step_end(self, name, ctx):
        self._progress.update(self._task_ids[name], completed=1, total=1)

    def on_step_skipped(self, name, reason, ctx):
        self._console.print(f"  [dim]{name}: skipped ({reason})[/dim]")

    def on_step_progress(self, name, done, total):
        if name in self._task_ids:
            self._progress.update(self._task_ids[name], completed=done, total=total)

    def on_pipeline_end(self, ctx):
        if self._progress:
            self._progress.stop()
```

`transient=True`: la barra desaparece al terminar, solo queda el summary table.
`total=None` en `add_task`: muestra spinner pulsante para steps de duracion variable
(ClearVoice, AssemblyAI). Se actualiza a progreso real cuando `on_step_progress` lo recibe.

### 3.7 Multi-archivo: Live + Group

Para cuando el pipeline procesa multiples archivos en paralelo o secuencialmente
mostrando progreso simultaneo:

```python
from rich.live import Live
from rich.console import Group

overall_progress = Progress(...)
file_progress = Progress(...)

with Live(Group(overall_progress, file_progress), console=console):
    for src in sources:
        file_task = file_progress.add_task(src.name, total=total_steps)
        pipeline.run(ctx_for(src))
        file_progress.update(file_task, completed=total_steps)
```

Util cuando wx4 procesa un directorio completo.

---

## 4. Oportunidades de refactorizacion entre steps

### 4.1 Logica de compresion compartida (ALTA PRIORIDAD)

`video_step._compress_video_from_audio()` y `compress_step` son casi identicos:

video_step:
```python
info = probe_video(video)
measured = measure_audio_lufs(video)
lufs = LufsInfo.from_measured(measured)
encoder = detect_best_encoder(force=None)
bitrate = calculate_video_bitrate(info, compress_ratio)
compressed = video.parent / f"{video.stem}..."
_compress_video(info, lufs, encoder, bitrate, compressed)
compressed.rename(video)
```

compress_step:
```python
info = probe_video(src)
measured = measure_audio_lufs(audio_source)
lufs = LufsInfo.from_measured(measured)
encoder = detect_best_encoder(force=None)
bitrate = calculate_video_bitrate(info, ctx.compress_ratio)
_compress_video(info, lufs, encoder, bitrate, out, progress_callback=ctx.step_progress)
```

Candidato para extraccion en `wx4/compress_video.py` (ya existe el modulo):
```python
def run_compression(src_video: Path, audio_source: Path, out: Path, ratio: float,
                    progress_callback=None) -> None:
    info = probe_video(src_video)
    lufs = LufsInfo.from_measured(measure_audio_lufs(audio_source)) if info.has_audio else LufsInfo.noop()
    encoder = detect_best_encoder(force=None)
    bitrate = calculate_video_bitrate(info, ratio)
    compress_video(info, lufs, encoder, bitrate, out, progress_callback=progress_callback)
```

### 4.2 Patron de limpieza de tmp files

Ambos `normalize_step` y `enhance_step` usan el mismo patron:
```python
tmp_raw = ...
tmp_norm = ...
try:
    ...
finally:
    for f in [tmp_raw, tmp_norm]:
        if f is not None and f.exists():
            f.unlink()
```

Candidato para extraccion como context manager en un modulo de utilidades:
```python
@contextmanager
def temp_files(*paths: Path):
    try:
        yield paths
    finally:
        for p in paths:
            if p is not None and p.exists():
                p.unlink()
```

Uso:
```python
with temp_files(tmp_raw, tmp_norm):
    extract_to_wav(ctx.src, tmp_raw)
    normalize_lufs(tmp_raw, tmp_norm)
    with atomic_output(out) as tmp_out:
        to_aac(tmp_norm, tmp_out)
```

### 4.3 Helper de timing

Como se describe en seccion 3.4, extraer `_with_timing()` a `wx4/context.py`
o a un modulo `wx4/step_utils.py` elimina 8 copias del patron.

### 4.4 Skip logic interna vs pipeline: eliminar doble check

Cuando el pipeline tenga `skip_fn` en `NamedStep`, los steps deben eliminar
su logica interna de skip. Esto requiere que `pipeline.run()` maneje `cache_hit`
via `skip_fn`, eliminando la necesidad de que `normalize_step` y `enhance_step`
chequeen `ctx.cache_hit` internamente.

---

## 5. Diseno propuesto: nuevo pipeline.py desde cero

### 5.1 Componentes

```
pipeline.py
  - SkipReason (StrEnum o Literal): "output_exists", "cache_hit", "force_skip", "always_runs"
  - StepDecision (dataclass): name, would_run, output_path, reason
  - NamedStep (dataclass): name, fn, output_fn, skip_fn, ctx_setter
  - PipelineObserver (Protocol): on_pipeline_start/end, on_step_start/end/skipped/progress
  - Pipeline (class): steps, observers, run(ctx), dry_run(ctx)
```

### 5.2 Pipeline.run() sin hardcodeo de cache_check

```python
def run(self, ctx: PipelineContext) -> PipelineContext:
    names = [s.name for s in self.steps]
    self._notify(lambda ob: ob.on_pipeline_start(names, ctx))
    try:
        for step in self.steps:
            out = step.output_fn(ctx) if step.output_fn else None
            skip_by_fn = step.skip_fn(ctx) if step.skip_fn else False
            skip_by_output = out is not None and out.exists() and not ctx.force

            if skip_by_fn or skip_by_output:
                reason = "cache_hit" if skip_by_fn else "output_exists"
                if out is not None and step.ctx_setter:
                    ctx = step.ctx_setter(ctx, out)
                self._notify(lambda ob: ob.on_step_skipped(step.name, reason, ctx))
                continue

            ctx = dataclasses.replace(ctx, step_progress=self._make_progress(step.name))
            self._notify(lambda ob: ob.on_step_start(step.name, ctx))
            ctx = step(ctx)
            self._notify(lambda ob: ob.on_step_end(step.name, ctx))
    finally:
        self._notify(lambda ob: ob.on_pipeline_end(ctx))
    return ctx
```

`_notify` es un helper: `for ob in self.observers: fn(ob)`.

### 5.3 Pipeline.dry_run() completamente puro

```python
def dry_run(self, ctx: PipelineContext) -> list[StepDecision]:
    simulated_ctx = _simulate_intermediate_files(ctx)
    decisions = []
    for step in self.steps:
        out = step.output_fn(simulated_ctx) if step.output_fn else None
        skip_by_fn = step.skip_fn(simulated_ctx) if step.skip_fn else False
        skip_by_output = out is not None and out.exists() and not simulated_ctx.force

        if out is None and not step.skip_fn:
            decisions.append(StepDecision(step.name, True, None, "always_runs"))
        elif skip_by_fn:
            decisions.append(StepDecision(step.name, False, out, "cache_hit"))
        elif skip_by_output:
            decisions.append(StepDecision(step.name, False, out, "output_exists"))
        else:
            decisions.append(StepDecision(step.name, True, out,
                             "force" if ctx.force else "not_exists"))
    return decisions
```

`_simulate_intermediate_files(ctx)` detecta archivos intermedios en disco
(enhanced, normalized) y retorna un ctx con esos campos poblados, sin llamar
`load_cache()`.

---

## 6. Diseno propuesto: nuevo cli.py desde cero

### 6.1 Estructura

```
cli.py
  - RichPipelineObserver (implementa PipelineObserver)
  - _build_dry_run_table(decisions) -> Table
  - _build_summary_table(ctx, elapsed) -> Table
  - _run_single(src, config, runtime_args, observer) -> PipelineContext
  - main() - argparse + loop sobre archivos/directorio
```

### 6.2 Separacion de responsabilidades

```
argparse -> PipelineConfig (que steps incluir)
         -> PipelineContext inicial (parametros de runtime)
         -> RichPipelineObserver (UI)
         -> Pipeline(steps, observers=[observer])
         -> pipeline.run(ctx) OR pipeline.dry_run(ctx)
```

`RichPipelineObserver` recibe un `Console` de Rich. Los steps no saben de esto.

### 6.3 --dry-run en CLI

```python
if args.dry_run:
    for src in sources:
        ctx = make_initial_ctx(src, args)
        decisions = pipeline.dry_run(ctx)
        console.print(_build_dry_run_table(src, decisions))
    return
```

La tabla muestra: Step | Would Run | Output Path | Reason

---

## 7. Dudas abiertas

### D1: Semantica de cache_hit en la logica de skip

Actualmente `cache_hit=True` significa "el enhanced.m4a ya existe, no re-procesar".
Si reimplementamos con `skip_fn=lambda ctx: ctx.cache_hit` en normalize y enhance,
el behavior es identico. Pero:

**Duda**: Cuando `cache_hit=True` y `normalized.m4a` NO existe en disco, el step
de normalize se deberia skipear (correcto) pero `ctx.normalized` quedaria como None.
Luego `enhance_step` leeria desde `ctx.normalized` (None) y usaria `ctx.src` en su lugar.
Esto es correcto (enhance puede operar sobre src) pero es el comportamiento esperado?
O deberia normalize ejecutarse incluso con cache_hit para asegurar que ctx.normalized esta seteado?

### D2: argparse vs typer para el nuevo cli.py

El cli.py actual usa `argparse`. Typer (0.12+) es mas moderno y usa type hints,
pero agrega una dependencia. Para un CLI complejo con muchos flags como wx4,
Typer reduce boilerplate significativamente.

**Duda**: Migrar a Typer o mantener argparse?

### D3: scope del helper de timing

Extraer `_with_timing()` a `context.py` acopla context.py a `time`. Alternativa:
crear `wx4/step_utils.py` como modulo de utilidades de steps (timing, atomic_output,
temp_files). Pero CLAUDE.md dice "no crear utilidades para operaciones de una sola vez".

**Duda**: Con 8 steps usando el mismo patron, es justificado el helper? O es
over-engineering?

### D4: PipelineObserver vs callbacks como lista de funciones

`PipelineObserver` como Protocol obliga a implementar todos los metodos.
Alternativa: callbacks registrados por evento:
```python
pipeline.on("step_start", lambda name, ctx: ...)
pipeline.on("step_end", lambda name, ctx: ...)
```
Mas flexible (no se necesita implementar todos), mas pythonico para uso simple.

**Duda**: Protocol unico o event hooks individuales?

### D5: KeyboardInterrupt y cleanup de tmp files

Si el usuario presiona Ctrl+C durante `normalize_step`, el `try/finally` limpia
los tmp files. Pero si el `Pipeline.run()` no captura `KeyboardInterrupt`,
el `finally` en la funcion step no se ejecuta si Python termina abruptamente.

En Python 3.12+, `KeyboardInterrupt` deriva de `BaseException`, el `finally`
SI se ejecuta en interrupciones normales. Pero si el proceso muere por SIGKILL,
no hay cleanup posible.

**Duda**: Hay que agregar signal handling en el Pipeline, o es suficiente
con el `try/finally` en cada step?

### D6: dry_run con --force

Con `--force`, dry_run muestra todos los steps como "would_run: True, reason: force".
Pero el step `cache_check` y `cache_save` no tienen output_fn y siempre ejecutan.
Como diferenciar "siempre ejecuta por diseno" de "ejecuta porque force"?

**Duda**: Agregar un campo `always_run: bool = False` a `NamedStep` para
distinguir estos casos en la tabla de dry-run?

### D7: Progreso de transcripcion (AssemblyAI)

`transcribe_step` no llama `ctx.step_progress` porque AssemblyAI es una API externa
sin streaming de progreso en el SDK actual. El step aparece como spinner pulsante
indefinidamente.

**Duda**: Deberia el observer mostrar un mensaje diferente para steps sin progreso
granular ("Transcribing... (waiting for AssemblyAI)")? O es suficiente el spinner?

### D8: Multi-archivo y observers

Si el pipeline procesa un directorio con N archivos, se crea una instancia de
`Pipeline` por archivo o una sola instancia con todos los archivos?

Si es una instancia por archivo: `RichPipelineObserver` recibe N llamadas a
`on_pipeline_start`. Hay que resetear el estado interno entre archivos.

**Duda**: Instancia de Pipeline por archivo (simple, stateless) o una sola
instancia con iteracion sobre archivos (stateful)?

---

## 8. Mapa de impacto de la reimplementacion

| Que cambia | Impacto en tests existentes |
|------------|----------------------------|
| Eliminar skip interno de normalize/enhance | test_steps.py: TestNormalizeStep, TestEnhanceStep |
| Agregar skip_fn a NamedStep | test_pipeline.py: TestNamedStep, TestBuildSteps |
| on_step_skipped gana parametro reason | test_pipeline.py: TestPipelineCallbacks |
| dry_run ya no ejecuta cache_check | test_pipeline.py: TestPipelineDryRun |
| Nuevo cli.py desde 0 | test_cli.py: todos |
| Extraer run_compression | test_steps.py: TestVideoStep, TestCompressStep |

Los modulos de nivel inferior (audio_extract, audio_normalize, audio_enhance,
audio_encode, format_srt, transcribe_aai, transcribe_wx3, video_black, video_merge,
compress_video, cache_io, speakers, format_convert) NO cambian.

---

## Fuentes

- [Rich Progress Display docs](https://rich.readthedocs.io/en/stable/progress.html)
- [Python Pipeline Design Patterns](https://www.startdataengineering.com/post/code-patterns/)
- [Atomic Writes in Python](https://tech-champion.com/data-science/stop-silent-data-loss-checksum-atomic-writes-temp-file-patterns/)
- [Python CLI Tools 2026: Click, Typer, argparse](https://devtoolbox.dedyn.io/blog/python-click-typer-cli-guide)
- [Python Dataclasses Guide 2026](https://devtoolbox.dedyn.io/blog/python-dataclasses-guide)
- [Modular Data Processing with Pipeline Approach](https://medium.com/@dkraczkowski/the-elegance-of-modular-data-processing-with-pythons-pipeline-approach-e63bec11d34f)
- [Python Decorators and Context Managers](https://medium.com/@svillasmith2/python-decorators-and-context-managers-b920e4f02c8a)
- [Python Dry Run CLI Patterns 2026](https://thelinuxcode.com/parsing-boolean-flags-with-argparse-in-python-patterns-i-trust-in-2026/)
