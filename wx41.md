# wx41: Analisis de Arquitectura Pipeline para Reimplementacion

Fecha: 2026-02-28
Objetivo: Analizar los steps actuales de wx4 para reimplementar pipeline.py y cli.py
desde cero con patrones idiomaticos Python 2026.

---

## 1. Mapa de lo que existe

### 1.1 Modulos de step (wx4/steps/)

| Step | Archivo | Salida declarada | Skip logica | Pipeline |
|------|---------|-----------------|-------------|----------|
| cache_check | steps/cache_check.py | ninguna | interna (lee cache JSON) | audio |
| normalize | steps/normalize.py | `_normalized.m4a` | interna + pipeline | audio |
| enhance | steps/enhance.py | `_enhanced.m4a` | interna + pipeline | audio |
| cache_save | steps/cache_save.py | ninguna | interna | audio |
| transcribe | steps/transcribe.py | `_timestamps.json` | solo pipeline | ambos |
| srt | steps/srt.py | `_timestamps.srt` | solo pipeline | ambos |
| video | steps/video.py | `_timestamps.mp4` | solo pipeline | **BIFUNCIONAL** (ver 2.9) |
| compress | steps/compress.py | `_compressed.mp4` | solo pipeline | video |

La columna Pipeline describe donde debe vivir el step en la nueva arquitectura.
`video_step` esta marcado como BIFUNCIONAL porque mezcla dos responsabilidades
que deben separarse (ver problema 2.9).

### 1.2 Patron uniforme en todos los steps

Cada step sigue esta estructura identica:

```
t0 = time.time()
[logica del step]
return dataclasses.replace(ctx, ..., timings={**ctx.timings, "nombre": time.time() - t0})
```

### 1.3 Comunicacion step -> UI (actual)

Los steps NO importan Rich. La cadena de reporte es:
```
step ---> ctx.step_progress(done, total) ---> Pipeline._make_step_progress() ---> callbacks.on_step_progress()
```
`ctx.step_progress` es un `Callable[[int, int], None]` inyectado por el pipeline antes de cada step.

---

## 2. Problemas identificados en la implementacion actual

### 2.1 Doble logica de skip en normalize_step y enhance_step

`Pipeline.run()` ya maneja skip via `output_fn + output.exists()`. Pero `normalize_step`
tiene adicionalmente:
```python
if ctx.cache_hit or out.exists():
    return dataclasses.replace(ctx, normalized=out if out.exists() else ctx.normalized, ...)
```

Resultado: cuando `cache_hit=True` y el archivo normalizado no existe,
`Pipeline.run()` llama al step (no skippea), el step retorna silenciosamente,
y los callbacks reciben `on_step_start` + `on_step_end` en lugar de `on_step_skipped`.
La UI muestra el step como ejecutado cuando no lo fue. Inconsistencia observable.

### 2.2 cache_check hardcodeado en Pipeline

En `Pipeline.run()` (lineas 69-78) y `Pipeline.dry_run()` (lineas 117-125):
```python
from wx4.steps import cache_check_step
cache_check_step_fn = None
for step in self.steps:
    if hasattr(step, "fn") and step.fn is cache_check_step:
        ...
```
El runner sabe el nombre de un step especifico. Es un code smell: el pipeline
deberia ser agnostico de implementaciones de step.

### 2.3 dry_run no es completamente dry

`Pipeline.dry_run()` ejecuta `cache_check_step_fn(ctx)` (linea 126), que llama
`load_cache()`, que lee el archivo `wx4_cache.json` del filesystem.
Un dry-run puro no deberia tener efectos secundarios de lectura de estado mutable.

### 2.4 model_cache importa Rich

`wx4/model_cache.py` importa `from rich.console import Console`.
Esto viola la restriccion de que los steps no dependan de UI.
El parametro `console` es Optional y se pasa como `None` desde `enhance_step`,
pero la dependencia de import existe a nivel de modulo.

### 2.5 Boilerplate de timing repetido 8 veces

Cada step: `t0 = time.time()` + `timings={**ctx.timings, "nombre": time.time() - t0}`.
Ocho copias del mismo patron. Sin extraccion, cambiar el mecanismo de timing
requiere editar 8 archivos.

### 2.6 Patron de escritura atomica repetido

`normalize_step` y `enhance_step` usan identico patron:
```python
tmp_out = out.with_suffix(".m4a.tmp")
if not to_aac(..., tmp_out):
    raise RuntimeError(...)
tmp_out.rename(out)
```
Y ambos tienen cleanup de tmp files con `try/finally`.

### 2.7 Logica de compresion duplicada

`video_step._compress_video_from_audio()` y `compress_step` ejecutan la misma
secuencia: `probe_video -> measure_audio_lufs -> LufsInfo -> detect_best_encoder
-> calculate_video_bitrate -> compress_video`. La diferencia es solo el destino
y la fuente de audio. Logica comun no extraida.

### 2.8 Pipeline monolitico sin distincion de tipo de medio

`Pipeline.build_steps()` retorna una lista unica independientemente de si el
input es audio (`.mp3`, `.m4a`) o video (`.mp4`, `.mkv`). Los problemas concretos:

- `compress_step` recibe audio como `ctx.src` y falla silenciosamente (retorna
  sin error en `probe_video()`, sin registrar nada). El pipeline marca el step
  como ejecutado cuando no lo fue.
- `transcribe_step` asume que `ctx.src` es audio. Para video input, el backend
  necesita extraer el audio primero, pero esa logica no esta explicitamente
  modelada en el pipeline.
- `cache_check` y `cache_save` leen/escriben cache del audio enhanced. Para
  video input, `ctx.enhanced` es None siempre: el cache nunca aplica.
- No existe un campo `ctx.media_type` ni logica de deteccion. `cli._has_video_stream()`
  existe en `cli.py` pero nunca se llama desde el flujo principal.

El resultado es un pipeline que corre steps incorrectos para el tipo de medio
sin emitir error, produciendo salidas incompletas en silencio.

### 2.9 video_step mezcla dos responsabilidades distintas

`steps/video.py` actualmente:
1. Genera un MP4 de video negro a partir del audio (responsabilidad A)
2. Comprime ese MP4 si `ctx.compress_ratio is not None` (responsabilidad B)

Problema A es exclusivo del pipeline de audio (input audio -> salida video).
Problema B es la misma logica de `compress_step` pero aplicada al video
generado. Al mezclarlas:

- No hay forma de agregar `compress_step` al AudioPipeline despues de `black_video_step`
  de forma declarativa: la compresion ya ocurre dentro del step.
- `compress_step` (el step separado) es redundante para input audio si
  `config.videooutput=True` y `config.compress_ratio` esta seteado: ambos steps
  comprimiran.
- Cambiar la logica de compresion requiere editar dos lugares.

La correccion es separar `video_step` en:
- `black_video_step`: exclusivamente audio -> black MP4 (sin compresion interna)
- Usar `compress_step` existente como paso declarativo posterior si se requiere

---

## 3. Patrones Python 2026 para la reimplementacion

### 3.1 Encadenado de steps: loop explicito con Protocol

El patron idiomatico 2026 para pipelines secuenciales con observabilidad es el
loop explicito con callbacks formalizados via Protocol:

```python
from typing import Protocol, runtime_checkable

@runtime_checkable
class PipelineObserver(Protocol):
    def on_pipeline_start(self, step_names: list[str], ctx: PipelineContext) -> None: ...
    def on_step_start(self, name: str, ctx: PipelineContext) -> None: ...
    def on_step_end(self, name: str, ctx: PipelineContext) -> None: ...
    def on_step_skipped(self, name: str, reason: str, ctx: PipelineContext) -> None: ...
    def on_step_progress(self, name: str, done: int, total: int) -> None: ...
    def on_pipeline_end(self, ctx: PipelineContext) -> None: ...
```

`@runtime_checkable` permite `isinstance(cb, PipelineObserver)` para validacion.
La firma de `on_step_skipped` incluye `reason: str` para que la UI muestre
"already_done" vs "user_skip" vs "output_exists".

Protocol unico (no event hooks individuales): obliga a quien implementa el observer
a declarar todos los metodos, lo que genera codigo mas sencillo y verificable en
el lado del implementador (un protocolo vs N callables). La verificacion de tipo
estatica detecta implementaciones incompletas.

### 3.2 Skip y resume: PipelineState (mecanismo canonico)

El mecanismo canonico 2026 para pipelines de procesamiento de archivos que deben
poder reanudarse es una combinacion de:

1. **Existencia del archivo de salida** para detectar steps completados
2. **Archivo de estado por fuente** para recordar la configuracion de skip usada
   por el usuario (que pasos saltar), de modo que re-ejecuciones sin `--force`
   respeten las decisiones originales

El archivo de estado es `{src.stem}.wx41.json` en el mismo directorio que la fuente.
`PipelineState` vive en `step_common.py`:

```python
@dataclass(frozen=True)
class PipelineState:
    completed_steps: tuple[str, ...] = ()
    user_skipped_steps: tuple[str, ...] = ()

    @classmethod
    def empty(cls) -> "PipelineState":
        return cls()

    @classmethod
    def load(cls, path: Path) -> "PipelineState":
        if not path.exists():
            return cls()
        data = json.loads(path.read_text(encoding="utf-8"))
        return cls(
            completed_steps=tuple(data.get("completed_steps", [])),
            user_skipped_steps=tuple(data.get("user_skipped_steps", [])),
        )

    def save(self, path: Path) -> None:
        payload = {
            "completed_steps": list(self.completed_steps),
            "user_skipped_steps": list(self.user_skipped_steps),
        }
        path.write_text(json.dumps(payload, ensure_ascii=False), encoding="utf-8")

    def was_done(self, step_name: str) -> bool:
        return step_name in self.completed_steps or step_name in self.user_skipped_steps

    def mark_complete(self, name: str) -> "PipelineState":
        return dataclasses.replace(self, completed_steps=(*self.completed_steps, name))

    def mark_user_skipped(self, name: str) -> "PipelineState":
        return dataclasses.replace(
            self, user_skipped_steps=(*self.user_skipped_steps, name)
        )
```

`frozen=True` + tuplas garantiza inmutabilidad. `mark_complete` y `mark_user_skipped`
retornan nuevas instancias (estilo funcional, consistente con `dataclasses.replace`
usado en todos los steps).

**Logica de skip en Pipeline.run()**:

```python
state_path = ctx.src.parent / f"{ctx.src.stem}.wx41.json"
state = PipelineState.empty() if ctx.force else PipelineState.load(state_path)

for step in self.steps:
    # 1. Skip configurado por el usuario (--skip-normalize, --skip-enhance)
    user_skip = step.skip_fn is not None and step.skip_fn(ctx)
    if user_skip:
        state = state.mark_user_skipped(step.name)
        state.save(state_path)
        self._notify(lambda ob: ob.on_step_skipped(step.name, "user_skip", ctx))
        continue

    # 2. Ya completado: archivo de salida existe O estado lo registra
    out = step.output_fn(ctx) if step.output_fn else None
    already_done = state.was_done(step.name) or (out is not None and out.exists())
    if already_done:
        if out is not None and out.exists() and step.ctx_setter:
            ctx = step.ctx_setter(ctx, out)
        self._notify(lambda ob: ob.on_step_skipped(step.name, "already_done", ctx))
        continue

    # 3. Ejecutar el step
    ctx = dataclasses.replace(ctx, step_progress=self._make_progress(step.name))
    self._notify(lambda ob: ob.on_step_start(step.name, ctx))
    ctx = step.fn(ctx)
    state = state.mark_complete(step.name)
    state.save(state_path)
    self._notify(lambda ob: ob.on_step_end(step.name, ctx))
```

**Comportamiento de --force**: `PipelineState.empty()` ignora el estado guardado.
Todos los steps se ejecutan (si su output_fn retorna None o el archivo no existe).
Al terminar, el estado se reescribe desde cero con la nueva configuracion.

**Comportamiento de re-ejecucion sin --force**: La instruccion original del usuario
(que steps saltar) se preserva via `user_skipped_steps`. Si el usuario corrio con
`--skip-enhance` la primera vez, reruns sin ese flag siguen saltando enhance porque
el estado lo recuerda. Solo `--force` resetea esto.

**Eliminado**: `cache_check_step`, `cache_save_step`, `ctx.cache_hit`, `ctx.cache`.
El mecanismo de estado del pipeline los reemplaza por completo, de forma mas
idiomatica y sin acoplar el pipeline a nombres de steps especificos.

### 3.3 Escritura atomica: contextmanager reutilizable (step_common.py)

El patron idiomatico 2026 para escrituras atomicas file-based usa `NamedTemporaryFile`
en lugar de un nombre fijo `.tmp`. Vive en `step_common.py`:

```python
@contextmanager
def atomic_output(target: Path):
    with tempfile.NamedTemporaryFile(
        delete=False, dir=target.parent, suffix=target.suffix + ".tmp"
    ) as tmp_file:
        tmp_path = Path(tmp_file.name)
    try:
        yield tmp_path
        tmp_path.rename(target)
    except Exception:
        if tmp_path.exists():
            tmp_path.unlink()
        raise
```

`NamedTemporaryFile` garantiza nombre unico (sin colisiones entre procesos).
`dir=target.parent` asegura que tmp y target estan en el mismo filesystem
para que `Path.rename()` sea atomico en POSIX.

### 3.4 Timing: decorator @timer (step_common.py)

Vive en `step_common.py` junto con `atomic_output` y `temp_files`. No en
`pipeline.py` (evita acoplar steps al modulo pipeline) ni en `context.py`
(evita acoplar context a `time` y `tempfile`).

```python
def timer(step_name: str):
    def decorator(fn):
        @functools.wraps(fn)
        def wrapper(ctx: PipelineContext) -> PipelineContext:
            t0 = time.perf_counter()
            result = fn(ctx)
            elapsed = time.perf_counter() - t0
            return dataclasses.replace(result, timings={**result.timings, step_name: elapsed})
        return wrapper
    return decorator
```

`time.perf_counter()` es monotonica y de alta resolucion. Reemplaza `time.time()`
en todos los steps.

### 3.5 Dry-run: simulacion pura que ignora --force

`Pipeline.dry_run()` muestra lo que el pipeline haria al reprocesar el archivo
en su estado ACTUAL: que ya esta hecho vs que falta. `--force` es irrelevante
para esta pregunta y se ignora siempre.

```python
def dry_run(self, ctx: PipelineContext) -> list[StepDecision]:
    state_path = ctx.src.parent / f"{ctx.src.stem}.wx41.json"
    state = PipelineState.load(state_path)  # siempre carga, ignora ctx.force
    simulated_ctx = _detect_intermediate_files(ctx)
    decisions = []
    for step in self.steps:
        user_skip = step.skip_fn is not None and step.skip_fn(simulated_ctx)
        if user_skip:
            decisions.append(StepDecision(step.name, False, None, "user_skip"))
            state = state.mark_user_skipped(step.name)
            continue

        out = step.output_fn(simulated_ctx) if step.output_fn else None
        already_done = state.was_done(step.name) or (out is not None and out.exists())
        if already_done:
            if out is not None and out.exists() and step.ctx_setter:
                simulated_ctx = step.ctx_setter(simulated_ctx, out)
            decisions.append(StepDecision(step.name, False, out, "already_done"))
        elif out is None and not step.skip_fn:
            decisions.append(StepDecision(step.name, True, None, "always_runs"))
        else:
            decisions.append(StepDecision(step.name, True, out, "not_done"))
    return decisions
```

`_detect_intermediate_files(ctx)` es una funcion pura que escanea el directorio
del src y puebla `ctx.normalized`, `ctx.enhanced`, etc. segun archivos existentes.
No llama a ningun proceso externo ni escribe nada.

### 3.6 UI: Rich Progress con Observer desacoplado

Rich es la version estable actual. El patron 2026 para pipelines CLI:

```python
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn

class RichPipelineObserver:
    def __init__(self, console):
        self._console = console
        self._progress: Optional[Progress] = None
        self._task_ids: dict[str, TaskID] = {}

    def reset(self) -> None:
        self._task_ids.clear()

    def on_pipeline_start(self, step_names, ctx):
        self._progress = Progress(
            SpinnerColumn(),
            TextColumn("[bold]{task.description}"),
            BarColumn(),
            TimeElapsedColumn(),
            transient=True,
            console=self._console,
        )
        self._progress.start()

    def on_step_start(self, name, ctx):
        task_id = self._progress.add_task(name, total=None)
        self._task_ids[name] = task_id

    def on_step_end(self, name, ctx):
        self._progress.update(self._task_ids[name], completed=1, total=1)
        self._progress.update(self._task_ids[name], visible=False)

    def on_step_skipped(self, name, reason, ctx):
        self._console.print(f"  [dim]{name}: skipped ({reason})[/dim]")

    def on_step_progress(self, name, done, total):
        if name in self._task_ids:
            self._progress.update(self._task_ids[name], completed=done, total=total)

    def on_pipeline_end(self, ctx):
        if self._progress:
            self._progress.stop()
```

`RichPipelineObserver` tiene un metodo `reset()` para limpiar `_task_ids` entre
archivos en modo multi-archivo. Una sola instancia del observer se reutiliza para
todos los archivos (D8 stateless: el Pipeline es stateless, el observer se resetea).

`transient=True`: la barra desaparece al terminar, solo queda el summary table.
`total=None` en `add_task`: muestra spinner pulsante para steps de duracion variable
(ClearVoice, AssemblyAI). Se actualiza a progreso real cuando `on_step_progress` lo recibe.

### 3.7 Multi-archivo: Live + Group

Para N archivos procesados secuencialmente mostrando progreso simultaneo:

```python
from rich.live import Live
from rich.console import Group

overall_progress = Progress(...)
file_progress = Progress(...)

with Live(Group(overall_progress, file_progress), console=console):
    for src in sources:
        file_task = file_progress.add_task(src.name, total=total_steps)
        observer.reset()
        orchestrator.run(src)
        file_progress.update(file_task, completed=total_steps)
```

IMPORTANTE: llamadas anidadas a `track()` o abrir dos `Progress` separados fuera
de un `Live` lanza `rich.errors.LiveError: Only one live display may be active at once`.
Siempre usar un unico `Live` con `Group` de multiples instancias `Progress`.

### 3.8 Signal handling: graceful shutdown (idiomatico Python)

El patron idiomatico Python 2026 para interrupcion graceful en un loop de archivos:

```python
import signal
import threading

_stop = threading.Event()

def _handle_signal(sig: int, _frame) -> None:
    _stop.set()
```

Registrado en `main()` antes del loop:
```python
signal.signal(signal.SIGINT, _handle_signal)
signal.signal(signal.SIGTERM, _handle_signal)
```

Loop de archivos con chequeo de stop:
```python
for src in sources:
    if _stop.is_set():
        break
    orchestrator.run(src)
```

`SIGINT` (Ctrl+C) y `SIGTERM` setean `_stop`. Si ocurre durante el procesamiento
de un archivo, el archivo actual termina (o Python propaga `KeyboardInterrupt`).
El archivo siguiente no se procesa. Los `try/finally` en cada step garantizan
limpieza de archivos temporales independientemente de como se interrumpa el step.

No se necesita signal handling en `Pipeline` ni en los steps: el `try/finally`
existente en cada step maneja la limpieza cuando `KeyboardInterrupt` (derivado de
`BaseException`) propaga hacia arriba.

### 3.9 Progreso de transcripcion AssemblyAI (polling idiomatico)

La API de AssemblyAI admite submit no-bloqueante + polling manual, lo que
permite reportar progreso real durante la espera. El flujo idiomatico:

```python
def transcribe_assemblyai(
    audio: Path,
    lang: Optional[str] = None,
    speakers: Optional[int] = None,
    progress_callback: Optional[Callable[[int, int]] = None,
) -> tuple[Path, Path]:
    aai.settings.api_key = os.environ.get("ASSEMBLY_AI_KEY") or _raise_no_key()
    config = aai.TranscriptionConfig(...)

    transcript = aai.Transcriber(config=config).submit(str(audio))
    if progress_callback:
        progress_callback(0, 3)  # uploading/queued

    _PROCESSING_STATUSES = {aai.TranscriptStatus.queued, aai.TranscriptStatus.processing}
    while transcript.status in _PROCESSING_STATUSES:
        time.sleep(3)
        transcript = transcript.wait_for_completion()
        if transcript.status == aai.TranscriptStatus.processing and progress_callback:
            progress_callback(1, 3)

    if transcript.status == aai.TranscriptStatus.error:
        raise RuntimeError(f"AssemblyAI error: {transcript.error}")

    if progress_callback:
        progress_callback(3, 3)
    ...
```

Los 3 pasos reportados son: (0) uploading/queued, (1) processing, (3) completed.
El observer Rich actualiza la barra de progreso del task "transcribe" con estos valores.

`transcribe_step` en wx41 pasa `ctx.step_progress` como `progress_callback`.

---

## 4. Oportunidades de refactorizacion entre steps

### 4.1 Logica de compresion compartida -> step_common.py (ALTA PRIORIDAD)

`video_step._compress_video_from_audio()` y `compress_step` son casi identicos.
Candidato para extraccion en `step_common.py`:

```python
def run_compression(
    src_video: Path,
    audio_source: Path,
    out: Path,
    ratio: float,
    progress_callback=None,
) -> None:
    info = probe_video(src_video)
    lufs = (
        LufsInfo.from_measured(measure_audio_lufs(audio_source))
        if info.has_audio
        else LufsInfo.noop()
    )
    encoder = detect_best_encoder(force=None)
    bitrate = calculate_video_bitrate(info, ratio)
    compress_video(info, lufs, encoder, bitrate, out, progress_callback=progress_callback)
```

`compress_step` y `black_video_step` (si comprime internamente) llaman a
`run_compression`. Elimina la duplicacion del problema 2.7.

### 4.2 Patron de limpieza de tmp files -> step_common.py

```python
@contextmanager
def temp_files(*paths: Path):
    try:
        yield paths
    finally:
        for p in paths:
            if p is not None and p.exists():
                p.unlink()
```

### 4.3 Modulo step_common.py

Todos los helpers compartidos por steps viven en `wx41/step_common.py`:
- `@timer(step_name: str)` - decorator de timing
- `atomic_output(target: Path)` - context manager de escritura atomica
- `temp_files(*paths: Path)` - context manager de limpieza de temporales
- `run_compression(...)` - logica de compresion compartida
- `PipelineState` - estado persistente del pipeline

No en `pipeline.py` (evita que steps importen de pipeline).
No en `context.py` (evita acoplar context a implementacion).

### 4.4 Skip logic interna -> eliminada

Con `PipelineState` manejando skip desde el exterior, los steps eliminan toda
logica interna de skip (`if ctx.cache_hit or out.exists():`). Los steps se
vuelven funciones puras: siempre ejecutan su logica cuando son llamados.

---

## 5. Diseno propuesto: nuevo pipeline.py desde cero

### 5.1 Tres flujos: AudioPipeline, VideoPipeline, MediaOrchestrator

```
MediaOrchestrator
    |-- detecta tipo de medio (audio / video)
    |-- construye PipelineContext con media_type
    |-- delega a AudioPipeline  (input audio)
    |-- delega a VideoPipeline  (input video)
```

**AudioPipeline** (input: .mp3, .m4a, .wav, .aac, .flac, .opus, .ogg):

```
normalize -> enhance -> transcribe -> srt -> black_video [-> compress]
```

`cache_check` y `cache_save` son ELIMINADOS como steps. El mecanismo de
`PipelineState` reemplaza toda su funcionalidad de forma mas idiomatica.
`compress` es opcional: solo se incluye si `config.compress_ratio is not None`.

`black_video_step` es el nuevo nombre de la responsabilidad A del actual
`video_step` (audio -> black MP4), sin logica de compresion interna.

**VideoPipeline** (input: .mp4, .mkv, .mov, .avi, .webm, .m4v):

```
transcribe -> srt -> compress
```

`compress_step` opera sobre `ctx.src` (el video original) en el VideoPipeline.
En el AudioPipeline opera sobre `ctx.video_out` (el video negro generado).
El step detecta cual usar via `ctx.media_type`.

**Reutilizacion de componentes (estilo declarativo)**:

```python
_TRANSCRIBE = NamedStep(
    "transcribe", transcribe_step,
    output_fn=lambda ctx: ctx.src.parent / f"{ctx.src.stem}_timestamps.json",
    ctx_setter=lambda ctx, p: dataclasses.replace(ctx, transcript_json=p),
)
_SRT = NamedStep(
    "srt", srt_step,
    output_fn=lambda ctx: ctx.src.parent / f"{ctx.src.stem}_timestamps.srt",
    ctx_setter=lambda ctx, p: dataclasses.replace(ctx, srt=p),
)

def build_audio_pipeline(config: PipelineConfig, observers) -> Pipeline:
    steps = [
        NamedStep(
            "normalize", normalize_step,
            output_fn=lambda ctx: ctx.src.parent / f"{ctx.src.stem}_normalized.m4a",
            skip_fn=lambda ctx: config.skip_normalize,
            ctx_setter=lambda ctx, p: dataclasses.replace(ctx, normalized=p),
        ),
        NamedStep(
            "enhance", enhance_step,
            output_fn=lambda ctx: ctx.src.parent / f"{ctx.src.stem}_enhanced.m4a",
            skip_fn=lambda ctx: config.skip_enhance,
            ctx_setter=lambda ctx, p: dataclasses.replace(ctx, enhanced=p),
        ),
        _TRANSCRIBE,
        _SRT,
        NamedStep(
            "black_video", black_video_step,
            output_fn=lambda ctx: ctx.src.parent / f"{ctx.src.stem}_timestamps.mp4",
            ctx_setter=lambda ctx, p: dataclasses.replace(ctx, video_out=p),
        ),
    ]
    if config.compress_ratio is not None:
        steps.append(NamedStep(
            "compress", compress_step,
            output_fn=lambda ctx: ctx.src.parent / f"{ctx.src.stem}_compressed.mp4",
            ctx_setter=lambda ctx, p: dataclasses.replace(ctx, video_compressed=p),
        ))
    return Pipeline(steps, observers)

def build_video_pipeline(config: PipelineConfig, observers) -> Pipeline:
    steps = [
        _TRANSCRIBE,
        _SRT,
        NamedStep(
            "compress", compress_step,
            output_fn=lambda ctx: ctx.src.parent / f"{ctx.src.stem}_compressed.mp4",
            ctx_setter=lambda ctx, p: dataclasses.replace(ctx, video_compressed=p),
        ),
    ]
    return Pipeline(steps, observers)
```

`skip_fn=lambda ctx: config.skip_normalize` captura `config` del closure de
`build_audio_pipeline`. Limpio y sin necesidad de almacenar skip flags en el ctx.

### 5.2 Step nuevo: black_video_step

```python
@timer("black_video")
def black_video_step(ctx: PipelineContext) -> PipelineContext:
    audio = ctx.enhanced or ctx.normalized or ctx.src
    out = audio.parent / f"{audio.stem}{INTERMEDIATE_BY_STEP['video']}"
    if not audio_to_black_video(audio, out):
        raise RuntimeError(f"audio_to_black_video failed for {audio.name}")
    return dataclasses.replace(ctx, video_out=out)
```

### 5.3 MediaOrchestrator

```python
class MediaOrchestrator:
    def __init__(self, config: PipelineConfig, observers):
        self._config = config
        self._observers = observers

    def run(self, src: Path) -> PipelineContext:
        media_type = detect_media_type(src)
        ctx = make_initial_ctx(src, self._config, media_type=media_type)
        pipeline = self._build_pipeline(media_type)
        return pipeline.run(ctx)

    def dry_run(self, src: Path) -> tuple[str, list[StepDecision]]:
        media_type = detect_media_type(src)
        ctx = make_initial_ctx(src, self._config, media_type=media_type)
        pipeline = self._build_pipeline(media_type)
        return media_type, pipeline.dry_run(ctx)

    def _build_pipeline(self, media_type: str) -> Pipeline:
        if media_type == MediaType.VIDEO:
            return build_video_pipeline(self._config, self._observers)
        return build_audio_pipeline(self._config, self._observers)
```

`detect_media_type` primero usa la extension (O(1), sin I/O) y solo llama
`_has_video_stream` (ffprobe) si la extension no esta en ninguna de las listas.

### 5.4 Componentes del modulo pipeline.py

```
pipeline.py
  - MediaType (clase con constantes AUDIO/VIDEO)
  - SkipReason (Literal): "already_done", "user_skip", "output_exists", "always_runs"
  - StepDecision (dataclass): name, would_run, output_path, reason
  - NamedStep (dataclass): name, fn, output_fn, skip_fn, ctx_setter
  - PipelineObserver (Protocol): on_pipeline_start/end, on_step_start/end/skipped/progress
  - Pipeline (class): steps, observers, run(ctx), dry_run(ctx)
  - build_audio_pipeline(config, observers) -> Pipeline
  - build_video_pipeline(config, observers) -> Pipeline
  - MediaOrchestrator (class): run(src), dry_run(src)
  - detect_media_type(src) -> str
  - make_initial_ctx(src, config, media_type) -> PipelineContext
  - _detect_intermediate_files(ctx) -> PipelineContext   [pure, para dry_run]
```

### 5.5 Pipeline.run() completo

```python
def run(self, ctx: PipelineContext) -> PipelineContext:
    state_path = ctx.src.parent / f"{ctx.src.stem}.wx41.json"
    state = PipelineState.empty() if ctx.force else PipelineState.load(state_path)
    names = [s.name for s in self.steps]
    self._notify(lambda ob: ob.on_pipeline_start(names, ctx))
    try:
        for step in self.steps:
            user_skip = step.skip_fn is not None and step.skip_fn(ctx)
            if user_skip:
                state = state.mark_user_skipped(step.name)
                state.save(state_path)
                self._notify(lambda ob: ob.on_step_skipped(step.name, "user_skip", ctx))
                continue

            out = step.output_fn(ctx) if step.output_fn else None
            already_done = state.was_done(step.name) or (out is not None and out.exists())
            if already_done:
                if out is not None and out.exists() and step.ctx_setter:
                    ctx = step.ctx_setter(ctx, out)
                self._notify(lambda ob: ob.on_step_skipped(step.name, "already_done", ctx))
                continue

            ctx = dataclasses.replace(ctx, step_progress=self._make_progress(step.name))
            self._notify(lambda ob: ob.on_step_start(step.name, ctx))
            ctx = step.fn(ctx)
            state = state.mark_complete(step.name)
            state.save(state_path)
            self._notify(lambda ob: ob.on_step_end(step.name, ctx))
    finally:
        self._notify(lambda ob: ob.on_pipeline_end(ctx))
    return ctx
```

`_notify` es un helper: `for ob in self.observers: fn(ob)`.

### 5.6 Pipeline.dry_run() completamente puro, ignora --force

```python
def dry_run(self, ctx: PipelineContext) -> list[StepDecision]:
    state_path = ctx.src.parent / f"{ctx.src.stem}.wx41.json"
    state = PipelineState.load(state_path)  # ignora ctx.force siempre
    simulated_ctx = _detect_intermediate_files(ctx)
    decisions = []
    for step in self.steps:
        user_skip = step.skip_fn is not None and step.skip_fn(simulated_ctx)
        if user_skip:
            decisions.append(StepDecision(step.name, False, None, "user_skip"))
            state = state.mark_user_skipped(step.name)
            continue

        out = step.output_fn(simulated_ctx) if step.output_fn else None
        already_done = state.was_done(step.name) or (out is not None and out.exists())
        if already_done:
            if out is not None and out.exists() and step.ctx_setter:
                simulated_ctx = step.ctx_setter(simulated_ctx, out)
            decisions.append(StepDecision(step.name, False, out, "already_done"))
        elif out is None and not step.skip_fn:
            decisions.append(StepDecision(step.name, True, None, "always_runs"))
        else:
            decisions.append(StepDecision(step.name, True, out, "not_done"))
    return decisions
```

---

## 6. Diseno propuesto: nuevo cli.py desde cero con Typer

### 6.1 Por que Typer

Typer (0.12+) usa type hints de Python para derivar el CLI automaticamente.
Elimina el boilerplate de `add_argument` + `type=` + `help=` repetido para
cada flag. Para un CLI con muchos parametros como wx41, reduce el codigo de
definicion de CLI a menos de la mitad comparado con argparse.

### 6.2 Estructura

```
cli.py
  - app: typer.Typer  (instancia global)
  - RichPipelineObserver (implementa PipelineObserver)
  - _build_dry_run_table(src, media_type, decisions) -> Table
  - _build_summary_table(ctx, elapsed) -> Table
  - _expand_paths(paths) -> list[Path]
  - main() decorado con @app.command()
```

### 6.3 Flujo principal con Typer + signal handling

```python
import signal
import threading
import typer
from pathlib import Path
from typing import Optional, Annotated

app = typer.Typer()
_stop = threading.Event()

def _handle_signal(sig: int, _frame) -> None:
    _stop.set()

@app.command()
def main(
    paths: Annotated[list[Path], typer.Argument(help="Audio or video files or directories")],
    compress: Annotated[Optional[float], typer.Option(help="Compression ratio (0-1)")] = None,
    backend: Annotated[str, typer.Option(help="Transcription backend: assemblyai or whisper")] = "assemblyai",
    force: Annotated[bool, typer.Option("--force", help="Ignore previous run state")] = False,
    skip_normalize: Annotated[bool, typer.Option("--skip-normalize")] = False,
    skip_enhance: Annotated[bool, typer.Option("--skip-enhance")] = False,
    dry_run: Annotated[bool, typer.Option("--dry-run", help="Show what would run without running")] = False,
) -> None:
    signal.signal(signal.SIGINT, _handle_signal)
    signal.signal(signal.SIGTERM, _handle_signal)

    console = Console()
    config = PipelineConfig(
        compress_ratio=compress,
        transcribe_backend=backend,
        force=force,
        skip_normalize=skip_normalize,
        skip_enhance=skip_enhance,
    )
    observer = RichPipelineObserver(console)
    orchestrator = MediaOrchestrator(config, observers=[observer])

    sources = _expand_paths(paths)
    for src in sources:
        if _stop.is_set():
            break
        observer.reset()
        if dry_run:
            media_type, decisions = orchestrator.dry_run(src)
            console.print(_build_dry_run_table(src, media_type, decisions))
        else:
            t0 = time.perf_counter()
            ctx = orchestrator.run(src)
            elapsed = time.perf_counter() - t0
            console.print(_build_summary_table(ctx, elapsed))

if __name__ == "__main__":
    app()
```

### 6.4 --dry-run con tipo de medio (ignora --force)

La tabla de dry-run muestra el pipeline seleccionado y el estado real del proceso:

```
Audio: recording.mp3
  Step         Would Run   Output                         Reason
  normalize    YES         recording_normalized.m4a       not_done
  enhance      YES         recording_enhanced.m4a         not_done
  transcribe   YES         recording_timestamps.json      not_done
  srt          YES         recording_timestamps.srt       not_done
  black_video  YES         recording_timestamps.mp4       not_done

Video: conference.mp4 (resuming)
  Step         Would Run   Output                         Reason
  transcribe   NO          conference_timestamps.json     already_done
  srt          NO          conference_timestamps.srt      already_done
  compress     YES         conference_compressed.mp4      not_done
```

---

## 7. Mapa de impacto de la reimplementacion

| Que cambia | Impacto en tests existentes |
|------------|----------------------------|
| Nuevo `black_video_step` (extraido de video_step) | Renombrar TestVideoStep a TestBlackVideoStep; eliminar tests de compresion interna |
| Eliminar `cache_check_step` y `cache_save_step` | Eliminar TestCacheCheckStep y TestCacheSaveStep |
| Eliminar skip interno de normalize/enhance | Eliminar tests de skip por cache_hit |
| `PipelineState` reemplaza `ctx.cache_hit` y `ctx.cache` | Fixtures de ctx pierden esos campos |
| `PipelineConfig` gana `skip_normalize`, `skip_enhance`, `transcribe_backend`, `force` | test_pipeline.py: fixtures de config |
| `on_step_skipped` gana `reason: str` | test_pipeline.py: TestPipelineCallbacks |
| dry_run ignora force | test_pipeline.py: TestPipelineDryRun |
| `build_audio_pipeline` / `build_video_pipeline` reemplazan `build_steps()` | test_pipeline.py: TestBuildSteps (split) |
| Nuevo `MediaOrchestrator` | Nuevo TestMediaOrchestrator |
| Typer reemplaza argparse | test_cli.py: todos |
| `run_compression` extraido a step_common.py | test_steps.py: TestVideoStep, TestCompressStep |
| AssemblyAI usa submit + polling | test_steps.py: TestTranscribeStep (mock submit) |

**Archivos nuevos**:
- `wx41/step_common.py` (timer, atomic_output, temp_files, run_compression, PipelineState)
- `wx41/steps/black_video.py` (extraido de steps/video.py)

**Archivos eliminados de wx41**:
- `wx41/steps/cache_check.py` (reemplazado por PipelineState)
- `wx41/steps/cache_save.py` (reemplazado por PipelineState)

**Archivos modificados**:
- `wx41/pipeline.py`: nuevo desde cero con PipelineState
- `wx41/context.py`: pierde `cache_hit`, `cache`; gana `media_type`, `skip_normalize`, `skip_enhance`
- `wx41/cli.py`: Typer + signal handling
- `wx41/steps/compress.py`: usa `ctx.video_out` cuando `ctx.media_type == "audio"`
- `wx41/steps/normalize.py`: elimina skip interno, aplica @timer
- `wx41/steps/enhance.py`: elimina skip interno, aplica @timer

Los modulos de nivel inferior (audio_extract, audio_normalize, audio_enhance,
audio_encode, format_srt, transcribe_aai, transcribe_wx3, video_black, video_merge,
compress_video, cache_io, speakers, format_convert) NO cambian, excepto
`transcribe_aai.py` que agrega el parametro `progress_callback` opcional.

---

## Fuentes

- [Rich Progress Display docs](https://rich.readthedocs.io/en/stable/progress.html)
- [Python Pipeline Design Patterns](https://www.startdataengineering.com/post/code-patterns/)
- [Atomic Writes in Python](https://tech-champion.com/data-science/stop-silent-data-loss-checksum-atomic-writes-temp-file-patterns/)
- [Typer docs 0.12+](https://typer.tiangolo.com/)
- [Python Dataclasses Guide 2026](https://devtoolbox.dedyn.io/blog/python-dataclasses-guide)
- [Modular Data Processing with Pipeline Approach](https://medium.com/@dkraczkowski/the-elegance-of-modular-data-processing-with-pythons-pipeline-approach-e63bec11d34f)
- [Python Decorators and Context Managers](https://medium.com/@svillasmith2/python-decorators-and-context-managers-b920e4f02c8a)
