# wx41: Analisis de Arquitectura Pipeline para Reimplementacion

Fecha: 2026-02-28
Objetivo: Analizar los steps actuales de wx4 para reimplementar pipeline.py y cli.py
desde cero con patrones idiomaticos Python 2026.

---

## 1. Mapa de lo que existe

### 1.1 Modulos de step (wx4/steps/)

| Step | Archivo | Salida declarada | Skip logica | Pipeline |
|------|---------|-----------------|-------------|----------|
| cache_check | steps/cache_check.py | ninguna | interna (lee cache JSON) | audio |
| normalize | steps/normalize.py | `_normalized.m4a` | interna + pipeline | audio |
| enhance | steps/enhance.py | `_enhanced.m4a` | interna + pipeline | audio |
| cache_save | steps/cache_save.py | ninguna | interna | audio |
| transcribe | steps/transcribe.py | `_timestamps.json` | solo pipeline | ambos |
| srt | steps/srt.py | `_timestamps.srt` | solo pipeline | ambos |
| video | steps/video.py | `_timestamps.mp4` | solo pipeline | **BIFUNCIONAL** (ver 2.9) |
| compress | steps/compress.py | `_compressed.mp4` | solo pipeline | video |

La columna Pipeline describe donde debe vivir el step en la nueva arquitectura.
`video_step` esta marcado como BIFUNCIONAL porque mezcla dos responsabilidades
que deben separarse (ver problema 2.9).

### 1.2 Patron uniforme en todos los steps

Cada step sigue esta estructura identica:

```
t0 = time.time()
[logica del step]
return dataclasses.replace(ctx, ..., timings={**ctx.timings, "nombre": time.time() - t0})
```

### 1.3 Comunicacion step -> UI (actual)

Los steps NO importan Rich. La cadena de reporte es:
```
step ---> ctx.step_progress(done, total) ---> Pipeline._make_step_progress() ---> callbacks.on_step_progress()
```
`ctx.step_progress` es un `Callable[[int, int], None]` inyectado por el pipeline antes de cada step.

---

## 2. Problemas identificados en la implementacion actual

### 2.1 Doble logica de skip en normalize_step y enhance_step

`Pipeline.run()` ya maneja skip via `output_fn + output.exists()`. Pero `normalize_step`
tiene adicionalmente:
```python
if ctx.cache_hit or out.exists():
    return dataclasses.replace(ctx, normalized=out if out.exists() else ctx.normalized, ...)
```

Resultado: cuando `cache_hit=True` y el archivo normalizado no existe,
`Pipeline.run()` llama al step (no skippea), el step retorna silenciosamente,
y los callbacks reciben `on_step_start` + `on_step_end` en lugar de `on_step_skipped`.
La UI muestra el step como ejecutado cuando no lo fue. Inconsistencia observable.

### 2.2 cache_check hardcodeado en Pipeline

En `Pipeline.run()` (lineas 69-78) y `Pipeline.dry_run()` (lineas 117-125):
```python
from wx4.steps import cache_check_step
cache_check_step_fn = None
for step in self.steps:
    if hasattr(step, "fn") and step.fn is cache_check_step:
        ...
```
El runner sabe el nombre de un step especifico. Es un code smell: el pipeline
deberia ser agnositco de implementaciones de step.

### 2.3 dry_run no es completamente dry

`Pipeline.dry_run()` ejecuta `cache_check_step_fn(ctx)` (linea 126), que llama
`load_cache()`, que lee el archivo `wx4_cache.json` del filesystem.
Un dry-run puro no deberia tener efectos secundarios de lectura de estado mutable.

### 2.4 model_cache importa Rich

`wx4/model_cache.py` importa `from rich.console import Console`.
Esto viola la restriccion de que los steps no dependan de UI.
El parametro `console` es Optional y se pasa como `None` desde `enhance_step`,
pero la dependencia de import existe a nivel de modulo.

### 2.5 Boilerplate de timing repetido 8 veces

Cada step: `t0 = time.time()` + `timings={**ctx.timings, "nombre": time.time() - t0}`.
Ocho copias del mismo patron. Sin extraccion, cambiar el mecanismo de timing
requiere editar 8 archivos.

### 2.6 Patron de escritura atomica repetido

`normalize_step` y `enhance_step` usan identico patron:
```python
tmp_out = out.with_suffix(".m4a.tmp")
if not to_aac(..., tmp_out):
    raise RuntimeError(...)
tmp_out.rename(out)
```
Y ambos tienen cleanup de tmp files con `try/finally`.

### 2.7 Logica de compresion duplicada

`video_step._compress_video_from_audio()` y `compress_step` ejecutan la misma
secuencia: `probe_video -> measure_audio_lufs -> LufsInfo -> detect_best_encoder
-> calculate_video_bitrate -> compress_video`. La diferencia es solo el destino
y la fuente de audio. Logica comun no extraida.

### 2.8 Pipeline monolitico sin distincion de tipo de medio

`Pipeline.build_steps()` retorna una lista unica independientemente de si el
input es audio (`.mp3`, `.m4a`) o video (`.mp4`, `.mkv`). Los problemas concretos:

- `compress_step` recibe audio como `ctx.src` y falla silenciosamente (retorna
  sin error en `probe_video()`, sin registrar nada). El pipeline marca el step
  como ejecutado cuando no lo fue.
- `transcribe_step` asume que `ctx.src` es audio. Para video input, el backend
  necesita extraer el audio primero, pero esa logica no esta explicitamente
  modelada en el pipeline.
- `cache_check` y `cache_save` leen/escriben cache del audio enhanced. Para
  video input, `ctx.enhanced` es None siempre: el cache nunca aplica.
- No existe un campo `ctx.media_type` ni logica de deteccion. `cli._has_video_stream()`
  existe en `cli.py` pero nunca se llama desde el flujo principal.

El resultado es un pipeline que corre steps incorrectos para el tipo de medio
sin emitir error, produciendo salidas incompletas en silencio.

### 2.9 video_step mezcla dos responsabilidades distintas

`steps/video.py` actualmente:
1. Genera un MP4 de video negro a partir del audio (responsabilidad A)
2. Comprime ese MP4 si `ctx.compress_ratio is not None` (responsabilidad B)

Problema A es exclusivo del pipeline de audio (input audio -> salida video).
Problema B es la misma logica de `compress_step` pero aplicada al video
generado. Al mezclarlas:

- No hay forma de aÃ±adir `compress_step` al AudioPipeline despues de `black_video_step`
  de forma declarativa: la compresion ya ocurre dentro del step.
- `compress_step` (el step separado) es redundante para input audio si
  `config.videooutput=True` y `config.compress_ratio` esta seteado: ambos steps
  comprimiran.
- Cambiar la logica de compresion requiere editar dos lugares.

La correccion es separar `video_step` en:
- `black_video_step`: exclusivamente audio -> black MP4 (sin compresion interna)
- Usar `compress_step` existente como paso declarativo posterior si se requiere

---

## 3. Patrones Python 2026 para la reimplementacion

### 3.1 Encadenado de steps: loop explicito con callbacks (recomendado)

El patron idiomatico 2026 para pipelines secuenciales con observabilidad es el
loop explicito con callbacks, NO `functools.reduce`. Razones:

```python
ctx = functools.reduce(lambda ctx, step: step(ctx), steps, ctx)
```
Es elegante pero: (a) imposibilita inyectar step_progress por step, (b) no permite
skip logic, (c) no hay punto de insercion para callbacks. No aplica aqui.

El patron correcto es el loop actual pero con Protocol formalizado:

```python
from typing import Protocol, runtime_checkable

@runtime_checkable
class PipelineObserver(Protocol):
    def on_pipeline_start(self, step_names: list[str], ctx: PipelineContext) -> None: ...
    def on_step_start(self, name: str, ctx: PipelineContext) -> None: ...
    def on_step_end(self, name: str, ctx: PipelineContext) -> None: ...
    def on_step_skipped(self, name: str, reason: str, ctx: PipelineContext) -> None: ...
    def on_step_progress(self, name: str, done: int, total: int) -> None: ...
    def on_pipeline_end(self, ctx: PipelineContext) -> None: ...
```

`@runtime_checkable` permite `isinstance(cb, PipelineObserver)` para validacion.
La firma de `on_step_skipped` gana un `reason: str` para que la UI muestre
"already done" vs "cache hit" vs "forced skip".

### 3.2 Skip y resume: puramente basado en archivos de salida

El patron 2026 para resume de pipeline de procesamiento de archivos es la
verificacion de existencia del archivo de salida (output sentinel), NO un archivo
de estado separado (SQLite, JSON de checkpoint):

```python
@dataclass
class NamedStep:
    name: str
    fn: Callable[[PipelineContext], PipelineContext]
    output_fn: Optional[Callable[[PipelineContext], Path]] = None
    skip_fn: Optional[Callable[[PipelineContext], bool]] = None
    ctx_setter: Optional[Callable[[PipelineContext, Path], PipelineContext]] = None
```

Agregar `skip_fn` a `NamedStep` permite manejar la logica de `cache_hit` desde
el exterior del step:
```python
NamedStep(
    "normalize",
    normalize_step,
    output_fn=_NORMALIZE_OUT,
    skip_fn=lambda ctx: ctx.cache_hit,
    ctx_setter=lambda ctx, p: dataclasses.replace(ctx, normalized=p),
)
```

Asi el pipeline puede llamar `on_step_skipped(name, "cache_hit", ctx)` correctamente
y la UI se entera.

### 3.3 Escritura atomica: contextmanager reutilizable

El patron idiomatico 2026 para escrituras atomicas file-based usa `NamedTemporaryFile`
en lugar de un nombre fijo `.tmp`. El nombre fijo colisiona si dos procesos operan
sobre el mismo archivo simultaneamente; `NamedTemporaryFile` garantiza unicidad:

```python
from contextlib import contextmanager
from pathlib import Path
import tempfile

@contextmanager
def atomic_output(target: Path):
    with tempfile.NamedTemporaryFile(
        delete=False, dir=target.parent, suffix=target.suffix + ".tmp"
    ) as tmp_file:
        tmp_path = Path(tmp_file.name)
    try:
        yield tmp_path
        tmp_path.rename(target)
    except Exception:
        if tmp_path.exists():
            tmp_path.unlink()
        raise
```

`NamedTemporaryFile` se cierra inmediatamente (el `with` solo reserva el nombre).
El step escribe a `tmp_path` via sus propias funciones (`to_aac`, etc.).
Al salir del contexto sin excepcion, `rename` mueve el tmp al destino final.

Uso en steps:
```python
with atomic_output(out) as tmp_out:
    if not to_aac(tmp_enh, tmp_out):
        raise RuntimeError(...)
```

`Path.rename()` en POSIX es atomico cuando src y dst estan en el mismo filesystem.
`dir=target.parent` garantiza que tmp y target estan en el mismo filesystem.

### 3.4 Timing: decorator @timer (standard 2026)

El patron idiomatico 2026 es un decorator parametrizado. La preocupacion de
testabilidad no aplica: los tests parchean las *dependencias* del step
(ej. `apply_clearvoice`, `extract_to_wav`), no el step mismo. El decorator
envuelve el step en tiempo de definicion y no interfiere con ninguno de esos patches.

```python
import functools
import time

def timer(step_name: str):
    def decorator(fn):
        @functools.wraps(fn)
        def wrapper(ctx: PipelineContext) -> PipelineContext:
            t0 = time.perf_counter()
            result = fn(ctx)
            elapsed = time.perf_counter() - t0
            return dataclasses.replace(result, timings={**result.timings, step_name: elapsed})
        return wrapper
    return decorator
```

Uso en cada step (elimina el boilerplate de t0 y timings):

```python
@timer("enhance")
def enhance_step(ctx: PipelineContext) -> PipelineContext:
    audio_input = ctx.normalized if ctx.normalized is not None else ctx.src
    cv = _get_model("MossFormer2", _load_clearvoice, None)
    ...
    return dataclasses.replace(ctx, enhanced=out)
```

`time.perf_counter()` (no `time.time()` ni `time.monotonic()`) es el standard 2026
para medir duraciones: es monotonica Y tiene la mayor resolucion disponible en
la plataforma. `time.time()` puede retroceder por ajustes de NTP.

### 3.5 Dry-run: simulacion pura sin efectos de lectura

Para que dry_run sea verdaderamente dry, el step `cache_check` no debe ejecutarse.
En su lugar, el pipeline puede simular su efecto consultando solo el filesystem
(los archivos de salida que cache_check detectaria):

```python
def dry_run(self, ctx: PipelineContext) -> list[StepDecision]:
    simulated_ctx = _simulate_cache_check(ctx)
    for step in self.steps:
        if step.name == "cache_check":
            decisions.append(StepDecision("cache_check", True, None, "always_runs"))
            continue
        out = step.output_fn(simulated_ctx) if step.output_fn else None
        skip = (
            (step.skip_fn and step.skip_fn(simulated_ctx))
            or (out is not None and out.exists() and not simulated_ctx.force)
        )
        ...
```

`_simulate_cache_check` es una funcion pura que replica la logica de deteccion de
archivos intermedios de `cache_check_step` sin llamar `load_cache()`.

### 3.6 UI: Rich Progress con Observer desacoplado

Rich 14.3.3 (enero 2026) es la version estable actual. El patron 2026 para
pipelines CLI fire-and-forget:

```python
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn

class RichPipelineObserver:
    def __init__(self, console):
        self._console = console
        self._progress: Optional[Progress] = None
        self._task_ids: dict[str, TaskID] = {}

    def on_pipeline_start(self, step_names, ctx):
        self._progress = Progress(
            SpinnerColumn(),
            TextColumn("[bold]{task.description}"),
            BarColumn(),
            TimeElapsedColumn(),
            transient=True,
            console=self._console,
        )
        self._progress.start()

    def on_step_start(self, name, ctx):
        task_id = self._progress.add_task(name, total=None)
        self._task_ids[name] = task_id

    def on_step_end(self, name, ctx):
        self._progress.update(self._task_ids[name], completed=1, total=1)
        self._progress.update(self._task_ids[name], visible=False)

    def on_step_skipped(self, name, reason, ctx):
        self._console.print(f"  [dim]{name}: skipped ({reason})[/dim]")

    def on_step_progress(self, name, done, total):
        if name in self._task_ids:
            self._progress.update(self._task_ids[name], completed=done, total=total)

    def on_pipeline_end(self, ctx):
        if self._progress:
            self._progress.stop()
```

`transient=True`: la barra desaparece al terminar, solo queda el summary table.
`total=None` en `add_task`: muestra spinner pulsante para steps de duracion variable
(ClearVoice, AssemblyAI). Se actualiza a progreso real cuando `on_step_progress` lo recibe.

### 3.7 Multi-archivo: Live + Group

Para cuando el pipeline procesa multiples archivos en paralelo o secuencialmente
mostrando progreso simultaneo:

```python
from rich.live import Live
from rich.console import Group

overall_progress = Progress(...)
file_progress = Progress(...)

with Live(Group(overall_progress, file_progress), console=console):
    for src in sources:
        file_task = file_progress.add_task(src.name, total=total_steps)
        pipeline.run(ctx_for(src))
        file_progress.update(file_task, completed=total_steps)
```

Util cuando wx4 procesa un directorio completo.

IMPORTANTE: llamadas anidadas a `track()` o abrir dos `Progress` separados fuera
de un `Live` lanza `rich.errors.LiveError: Only one live display may be active at once`.
Siempre usar un unico `Live` con `Group` de multiples instancias `Progress`.

---

## 4. Oportunidades de refactorizacion entre steps

### 4.1 Logica de compresion compartida (ALTA PRIORIDAD)

`video_step._compress_video_from_audio()` y `compress_step` son casi identicos:

video_step:
```python
info = probe_video(video)
measured = measure_audio_lufs(video)
lufs = LufsInfo.from_measured(measured)
encoder = detect_best_encoder(force=None)
bitrate = calculate_video_bitrate(info, compress_ratio)
compressed = video.parent / f"{video.stem}..."
_compress_video(info, lufs, encoder, bitrate, compressed)
compressed.rename(video)
```

compress_step:
```python
info = probe_video(src)
measured = measure_audio_lufs(audio_source)
lufs = LufsInfo.from_measured(measured)
encoder = detect_best_encoder(force=None)
bitrate = calculate_video_bitrate(info, ctx.compress_ratio)
_compress_video(info, lufs, encoder, bitrate, out, progress_callback=ctx.step_progress)
```

Candidato para extraccion en `wx4/compress_video.py` (ya existe el modulo):
```python
def run_compression(src_video: Path, audio_source: Path, out: Path, ratio: float,
                    progress_callback=None) -> None:
    info = probe_video(src_video)
    lufs = LufsInfo.from_measured(measure_audio_lufs(audio_source)) if info.has_audio else LufsInfo.noop()
    encoder = detect_best_encoder(force=None)
    bitrate = calculate_video_bitrate(info, ratio)
    compress_video(info, lufs, encoder, bitrate, out, progress_callback=progress_callback)
```

### 4.2 Patron de limpieza de tmp files

Ambos `normalize_step` y `enhance_step` usan el mismo patron:
```python
tmp_raw = ...
tmp_norm = ...
try:
    ...
finally:
    for f in [tmp_raw, tmp_norm]:
        if f is not None and f.exists():
            f.unlink()
```

Candidato para extraccion como context manager en un modulo de utilidades:
```python
@contextmanager
def temp_files(*paths: Path):
    try:
        yield paths
    finally:
        for p in paths:
            if p is not None and p.exists():
                p.unlink()
```

Uso:
```python
with temp_files(tmp_raw, tmp_norm):
    extract_to_wav(ctx.src, tmp_raw)
    normalize_lufs(tmp_raw, tmp_norm)
    with atomic_output(out) as tmp_out:
        to_aac(tmp_norm, tmp_out)
```

### 4.3 Decorator de timing

Como se describe en seccion 3.4, aplicar `@timer("nombre")` a cada step elimina
las 8 copias del patron `t0/timings`. El decorator se define una vez en `pipeline.py`
(ya que es parte del contrato del pipeline con los steps) o en `wx4/step_utils.py`.

### 4.4 Skip logic interna vs pipeline: eliminar doble check

Cuando el pipeline tenga `skip_fn` en `NamedStep`, los steps deben eliminar
su logica interna de skip. Esto requiere que `pipeline.run()` maneje `cache_hit`
via `skip_fn`, eliminando la necesidad de que `normalize_step` y `enhance_step`
chequeen `ctx.cache_hit` internamente.

---

## 5. Diseno propuesto: nuevo pipeline.py desde cero

### 5.1 Tres flujos: AudioPipeline, VideoPipeline, MediaOrchestrator

La arquitectura propuesta reemplaza el pipeline monolitico por dos pipelines
declarativos especializados y un orquestador que decide cual usar:

```
MediaOrchestrator
    |-- detecta tipo de medio (audio / video)
    |-- construye PipelineContext con media_type
    |-- delega a AudioPipeline  (input audio)
    |-- delega a VideoPipeline  (input video)
```

**AudioPipeline** (input: .mp3, .m4a, .wav, .aac, .flac, .opus, .ogg):

```
cache_check -> normalize -> enhance -> cache_save
    -> transcribe -> srt -> black_video [-> compress]
```

`black_video_step` es el nuevo nombre de la responsabilidad A del actual
`video_step` (audio -> black MP4), sin logica de compresion interna.
`compress` es opcional y se incluye solo si `config.compress_ratio is not None`.

**VideoPipeline** (input: .mp4, .mkv, .mov, .avi, .webm, .m4v):

```
transcribe -> srt -> compress
```

`compress_step` ya existe y opera sobre `ctx.src` (el video original).
Si en el futuro se quiere mejorar el audio del video antes de comprimir,
se insertan `normalize` y `enhance` antes de `transcribe`.

**Reutilizacion de componentes (estilo declarativo)**:

```python
_TRANSCRIBE = NamedStep(
    "transcribe", transcribe_step, _transcript_json,
    ctx_setter=lambda ctx, p: dataclasses.replace(ctx, transcript_json=p),
)
_SRT = NamedStep(
    "srt", srt_step, _srt_out,
    ctx_setter=lambda ctx, p: dataclasses.replace(ctx, srt=p),
)

def build_audio_pipeline(config: PipelineConfig, observers) -> Pipeline:
    steps = [
        NamedStep("cache_check", cache_check_step),
        NamedStep("normalize", normalize_step, _NORMALIZE_OUT,
                  skip_fn=lambda ctx: ctx.cache_hit,
                  ctx_setter=lambda ctx, p: dataclasses.replace(ctx, normalized=p)),
        NamedStep("enhance", enhance_step, _ENHANCE_OUT,
                  skip_fn=lambda ctx: ctx.cache_hit,
                  ctx_setter=lambda ctx, p: dataclasses.replace(ctx, enhanced=p)),
        NamedStep("cache_save", cache_save_step),
        _TRANSCRIBE,
        _SRT,
        NamedStep("black_video", black_video_step, _VIDEO_OUT,
                  ctx_setter=lambda ctx, p: dataclasses.replace(ctx, video_out=p)),
    ]
    if config.compress_ratio is not None:
        steps.append(NamedStep("compress", compress_step, _COMPRESS_OUT,
                               ctx_setter=lambda ctx, p: dataclasses.replace(ctx, video_compressed=p)))
    return Pipeline(steps, observers)

def build_video_pipeline(config: PipelineConfig, observers) -> Pipeline:
    steps = [
        _TRANSCRIBE,
        _SRT,
        NamedStep("compress", compress_step, _COMPRESS_OUT,
                  ctx_setter=lambda ctx, p: dataclasses.replace(ctx, video_compressed=p)),
    ]
    return Pipeline(steps, observers)
```

Los objetos `_TRANSCRIBE` y `_SRT` son instancias compartidas entre ambos
pipelines. `NamedStep` es un dataclass inmutable, por lo que compartir
instancias es seguro.

### 5.2 Step nuevo: black_video_step

Extraccion de la responsabilidad A del actual `video_step`. El step resultante
es una funcion pura sin logica de compresion interna:

```python
@timer("black_video")
def black_video_step(ctx: PipelineContext) -> PipelineContext:
    audio = ctx.enhanced or ctx.normalized or ctx.src
    out = audio.parent / f"{audio.stem}{INTERMEDIATE_BY_STEP['video']}"
    if not audio_to_black_video(audio, out):
        raise RuntimeError(f"audio_to_black_video failed for {audio.name}")
    return dataclasses.replace(ctx, video_out=out)
```

La compresion posterior (si `config.compress_ratio is not None`) la realiza
`compress_step` como step declarativo separado en el AudioPipeline.
`compress_step` recibe `ctx.video_out` como fuente cuando `ctx.src` es audio
(ver ajuste en seccion 4.1).

### 5.3 MediaOrchestrator

```python
@dataclass
class MediaType:
    AUDIO = "audio"
    VIDEO = "video"

def detect_media_type(src: Path) -> str:
    if src.suffix.lower() in _AUDIO_EXTENSIONS:
        return MediaType.AUDIO
    if src.suffix.lower() in _VIDEO_EXTENSIONS:
        return MediaType.VIDEO
    has_video = _has_video_stream(src)
    if has_video is True:
        return MediaType.VIDEO
    return MediaType.AUDIO

class MediaOrchestrator:
    def __init__(self, config: PipelineConfig, observers):
        self._config = config
        self._observers = observers

    def run(self, src: Path) -> PipelineContext:
        media_type = detect_media_type(src)
        ctx = make_initial_ctx(src, self._config, media_type=media_type)
        if media_type == MediaType.VIDEO:
            pipeline = build_video_pipeline(self._config, self._observers)
        else:
            pipeline = build_audio_pipeline(self._config, self._observers)
        return pipeline.run(ctx)

    def dry_run(self, src: Path) -> tuple[str, list[StepDecision]]:
        media_type = detect_media_type(src)
        ctx = make_initial_ctx(src, self._config, media_type=media_type)
        if media_type == MediaType.VIDEO:
            pipeline = build_video_pipeline(self._config, self._observers)
        else:
            pipeline = build_audio_pipeline(self._config, self._observers)
        return media_type, pipeline.dry_run(ctx)
```

`detect_media_type` primero usa la extension (O(1), sin I/O) y solo llama
`_has_video_stream` (ffprobe) si la extension no esta en ninguna de las listas.

`PipelineContext` gana un campo `media_type: str` para que observers y steps
puedan consultarlo si lo necesitan.

### 5.4 Componentes del modulo pipeline.py

```
pipeline.py
  - SkipReason (Literal): "output_exists", "cache_hit", "force_skip", "always_runs"
  - StepDecision (dataclass): name, would_run, output_path, reason
  - NamedStep (dataclass): name, fn, output_fn, skip_fn, ctx_setter
  - PipelineObserver (Protocol): on_pipeline_start/end, on_step_start/end/skipped/progress
  - Pipeline (class): steps, observers, run(ctx), dry_run(ctx)
  - build_audio_pipeline(config, observers) -> Pipeline
  - build_video_pipeline(config, observers) -> Pipeline
  - MediaOrchestrator (class): run(src), dry_run(src)
  - detect_media_type(src) -> str
```

### 5.5 Pipeline.run() sin hardcodeo de cache_check

```python
def run(self, ctx: PipelineContext) -> PipelineContext:
    names = [s.name for s in self.steps]
    self._notify(lambda ob: ob.on_pipeline_start(names, ctx))
    try:
        for step in self.steps:
            out = step.output_fn(ctx) if step.output_fn else None
            skip_by_fn = step.skip_fn(ctx) if step.skip_fn else False
            skip_by_output = out is not None and out.exists() and not ctx.force

            if skip_by_fn or skip_by_output:
                reason = "cache_hit" if skip_by_fn else "output_exists"
                if out is not None and step.ctx_setter:
                    ctx = step.ctx_setter(ctx, out)
                self._notify(lambda ob: ob.on_step_skipped(step.name, reason, ctx))
                continue

            ctx = dataclasses.replace(ctx, step_progress=self._make_progress(step.name))
            self._notify(lambda ob: ob.on_step_start(step.name, ctx))
            ctx = step.fn(ctx)
            self._notify(lambda ob: ob.on_step_end(step.name, ctx))
    finally:
        self._notify(lambda ob: ob.on_pipeline_end(ctx))
    return ctx
```

`_notify` es un helper: `for ob in self.observers: fn(ob)`.

### 5.6 Pipeline.dry_run() completamente puro

```python
def dry_run(self, ctx: PipelineContext) -> list[StepDecision]:
    simulated_ctx = _simulate_intermediate_files(ctx)
    decisions = []
    for step in self.steps:
        out = step.output_fn(simulated_ctx) if step.output_fn else None
        skip_by_fn = step.skip_fn(simulated_ctx) if step.skip_fn else False
        skip_by_output = out is not None and out.exists() and not simulated_ctx.force

        if out is None and not step.skip_fn:
            decisions.append(StepDecision(step.name, True, None, "always_runs"))
        elif skip_by_fn:
            decisions.append(StepDecision(step.name, False, out, "cache_hit"))
        elif skip_by_output:
            decisions.append(StepDecision(step.name, False, out, "output_exists"))
        else:
            decisions.append(StepDecision(step.name, True, out,
                             "force" if ctx.force else "not_exists"))
    return decisions
```

`_simulate_intermediate_files(ctx)` detecta archivos intermedios en disco
(enhanced, normalized) y retorna un ctx con esos campos poblados, sin llamar
`load_cache()`.

---

## 6. Diseno propuesto: nuevo cli.py desde cero

### 6.1 Estructura

```
cli.py
  - RichPipelineObserver (implementa PipelineObserver)
  - _build_dry_run_table(src, media_type, decisions) -> Table
  - _build_summary_table(ctx, elapsed) -> Table
  - _run_single(src, orchestrator) -> PipelineContext
  - main() - argparse + MediaOrchestrator + loop sobre archivos/directorio
```

### 6.2 Separacion de responsabilidades

```
argparse -> PipelineConfig (que steps incluir, compress_ratio, backend)
         -> RichPipelineObserver (UI, recibe Console de Rich)
         -> MediaOrchestrator(config, observers=[observer])
         -> orchestrator.run(src) OR orchestrator.dry_run(src)
```

El CLI ya no construye pipelines directamente. Solo construye el orquestador
y delega. `RichPipelineObserver` recibe eventos de cualquiera de los dos pipelines
sin saber cual esta activo. Los steps no saben de Rich.

### 6.3 Flujo principal con orquestador

```python
def main():
    args = _parse_args()
    console = Console()
    config = PipelineConfig(
        compress_ratio=args.compress,
        transcribe_backend=args.backend,
        force=args.force,
    )
    observer = RichPipelineObserver(console)
    orchestrator = MediaOrchestrator(config, observers=[observer])

    sources = _expand_paths(args.paths)
    for src in sources:
        if args.dry_run:
            media_type, decisions = orchestrator.dry_run(src)
            console.print(_build_dry_run_table(src, media_type, decisions))
        else:
            orchestrator.run(src)
```

### 6.4 --dry-run con tipo de medio

La tabla de dry-run gana la columna `Media Type` para que el usuario vea
que pipeline se selecciono:

```
Audio: recording.mp3
  Step          Would Run    Output                      Reason
  cache_check   YES          -                           always_runs
  normalize     YES          recording_normalized.m4a    not_exists
  enhance       YES          recording_enhanced.m4a      not_exists
  cache_save    YES          -                           always_runs
  transcribe    YES          recording_timestamps.json   not_exists
  srt           YES          recording_timestamps.srt    not_exists
  black_video   YES          recording_timestamps.mp4    not_exists

Video: conference.mp4
  Step          Would Run    Output                      Reason
  transcribe    YES          conference_timestamps.json  not_exists
  srt           YES          conference_timestamps.srt   not_exists
  compress      NO           conference_compressed.mp4   output_exists
```

---

## 7. Dudas abiertas

### D1: Semantica de cache_hit en la logica de skip

Actualmente `cache_hit=True` significa "el enhanced.m4a ya existe, no re-procesar".
Si reimplementamos con `skip_fn=lambda ctx: ctx.cache_hit` en normalize y enhance,
el behavior es identico. Pero:

**Duda**: Cuando `cache_hit=True` y `normalized.m4a` NO existe en disco, el step
de normalize se deberia skipear (correcto) pero `ctx.normalized` quedaria como None.
Luego `enhance_step` leeria desde `ctx.normalized` (None) y usaria `ctx.src` en su lugar.
Esto es correcto (enhance puede operar sobre src) pero es el comportamiento esperado?
O deberia normalize ejecutarse incluso con cache_hit para asegurar que ctx.normalized esta seteado?

### D2: argparse vs typer para el nuevo cli.py

El cli.py actual usa `argparse`. Typer (0.12+) es mas moderno y usa type hints,
pero agrega una dependencia. Para un CLI complejo con muchos flags como wx4,
Typer reduce boilerplate significativamente.

**Duda**: Migrar a Typer o mantener argparse?

### D3: ubicacion del decorator @timer y helpers de step

El decorator `@timer`, `atomic_output` y `temp_files` son utilizados por los 8 steps.
Tres opciones:
- Definirlos en `pipeline.py` (acoplamiento paso-pipeline)
- Definirlos en `wx4/step_utils.py` (nuevo modulo de utilidades)
- Definirlos en `wx4/context.py` (acopla context a `time` y `tempfile`)

**Duda**: Cual es el modulo correcto para estas utilidades compartidas de steps?
`step_utils.py` parece el mas limpio pero agrega un modulo nuevo.

### D4: PipelineObserver vs callbacks como lista de funciones

`PipelineObserver` como Protocol obliga a implementar todos los metodos.
Alternativa: callbacks registrados por evento:
```python
pipeline.on("step_start", lambda name, ctx: ...)
pipeline.on("step_end", lambda name, ctx: ...)
```
Mas flexible (no se necesita implementar todos), mas pythonico para uso simple.

**Duda**: Protocol unico o event hooks individuales?

### D5: KeyboardInterrupt y cleanup de tmp files

Si el usuario presiona Ctrl+C durante `normalize_step`, el `try/finally` limpia
los tmp files. Pero si el `Pipeline.run()` no captura `KeyboardInterrupt`,
el `finally` en la funcion step no se ejecuta si Python termina abruptamente.

En Python 3.12+, `KeyboardInterrupt` deriva de `BaseException`, el `finally`
SI se ejecuta en interrupciones normales. Pero si el proceso muere por SIGKILL,
no hay cleanup posible.

**Duda**: Hay que agregar signal handling en el Pipeline, o es suficiente
con el `try/finally` en cada step?

### D6: dry_run con --force

Con `--force`, dry_run muestra todos los steps como "would_run: True, reason: force".
Pero el step `cache_check` y `cache_save` no tienen output_fn y siempre ejecutan.
Como diferenciar "siempre ejecuta por diseno" de "ejecuta porque force"?

**Duda**: Agregar un campo `always_run: bool = False` a `NamedStep` para
distinguir estos casos en la tabla de dry-run?

### D7: Progreso de transcripcion (AssemblyAI)

`transcribe_step` no llama `ctx.step_progress` porque AssemblyAI es una API externa
sin streaming de progreso en el SDK actual. El step aparece como spinner pulsante
indefinidamente.

**Duda**: Deberia el observer mostrar un mensaje diferente para steps sin progreso
granular ("Transcribing... (waiting for AssemblyAI)")? O es suficiente el spinner?

### D8: Multi-archivo y observers

Si el pipeline procesa un directorio con N archivos, se crea una instancia de
`Pipeline` por archivo o una sola instancia con todos los archivos?

Si es una instancia por archivo: `RichPipelineObserver` recibe N llamadas a
`on_pipeline_start`. Hay que resetear el estado interno entre archivos.

**Duda**: Instancia de Pipeline por archivo (simple, stateless) o una sola
instancia con iteracion sobre archivos (stateful)?

---

## 8. Mapa de impacto de la reimplementacion

| Que cambia | Impacto en tests existentes |
|------------|----------------------------|
| Nuevo `black_video_step` (extraido de video_step) | test_steps.py: TestVideoStep -> renombrar a TestBlackVideoStep; eliminar tests de compresion interna |
| Eliminar compresion interna de video_step | test_steps.py: TestVideoStep (eliminar assert sobre compress) |
| Eliminar skip interno de normalize/enhance | test_steps.py: TestNormalizeStep, TestEnhanceStep |
| Agregar skip_fn a NamedStep | test_pipeline.py: TestNamedStep, TestBuildSteps |
| on_step_skipped gana parametro reason | test_pipeline.py: TestPipelineCallbacks |
| dry_run ya no ejecuta cache_check | test_pipeline.py: TestPipelineDryRun |
| Separar build_audio_pipeline / build_video_pipeline | test_pipeline.py: TestBuildSteps (split en dos clases) |
| Nuevo MediaOrchestrator | test_pipeline.py: nuevo TestMediaOrchestrator |
| ctx gana campo media_type | test_pipeline.py: todos los fixtures de ctx |
| Nuevo cli.py desde 0 con orquestador | test_cli.py: todos |
| Extraer run_compression (seccion 4.1) | test_steps.py: TestVideoStep, TestCompressStep |

**Archivos nuevos**:
- `wx4/steps/black_video.py` (extraido de `steps/video.py`)

**Archivos eliminados**:
- `wx4/steps/video.py` (reemplazado por `black_video.py`)

**Archivos modificados**:
- `wx4/pipeline.py`: reemplazar `build_steps()` por `build_audio_pipeline()`,
  `build_video_pipeline()`, y `MediaOrchestrator`
- `wx4/context.py`: agregar campo `media_type: str`
- `wx4/cli.py`: reemplazar loop directo por `MediaOrchestrator`
- `wx4/steps/compress.py`: ajustar para usar `ctx.video_out` cuando
  `ctx.media_type == MediaType.AUDIO` (ver seccion 4.1)

Los modulos de nivel inferior (audio_extract, audio_normalize, audio_enhance,
audio_encode, format_srt, transcribe_aai, transcribe_wx3, video_black, video_merge,
compress_video, cache_io, speakers, format_convert) NO cambian.

---

## Fuentes

- [Rich Progress Display docs](https://rich.readthedocs.io/en/stable/progress.html)
- [Python Pipeline Design Patterns](https://www.startdataengineering.com/post/code-patterns/)
- [Atomic Writes in Python](https://tech-champion.com/data-science/stop-silent-data-loss-checksum-atomic-writes-temp-file-patterns/)
- [Python CLI Tools 2026: Click, Typer, argparse](https://devtoolbox.dedyn.io/blog/python-click-typer-cli-guide)
- [Python Dataclasses Guide 2026](https://devtoolbox.dedyn.io/blog/python-dataclasses-guide)
- [Modular Data Processing with Pipeline Approach](https://medium.com/@dkraczkowski/the-elegance-of-modular-data-processing-with-pythons-pipeline-approach-e63bec11d34f)
- [Python Decorators and Context Managers](https://medium.com/@svillasmith2/python-decorators-and-context-managers-b920e4f02c8a)
- [Python Dry Run CLI Patterns 2026](https://thelinuxcode.com/parsing-boolean-flags-with-argparse-in-python-patterns-i-trust-in-2026/)
